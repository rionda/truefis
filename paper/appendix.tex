\appendix
\section{Appendix}
We now present a sketch of the proof of Thm.~\ref{thm:eapproxempir}. Before we start, we
need to introduce some additional settings and terminology.

As in Sect.~\ref{sec:prelvcdim}, let $D$ be a domain and $\range$ be a
collection of subsets from $D$. Let $S=\{t_1,\dotsc,t_\ell\}$ be a bag of $\ell$
elements from $D$. For each $t_i$, $1\le i\le \ell$, let $\sigma_i$ be a
Rademacher random variable, i.e., a random variable taking value $-1$ or $1$,
each with probability $1/2$. The random variables $\sigma_i$ are independent.
For any $r\in\range$, the quantity
\[
	R_S(r)=\frac{1}{\ell}\sum_{i=1}^\ell \sigma_i\mathds{1}_r(t_i)
\]
is known as the \emph{sample Rademacher average} of $r$ in the set $S$. The
\emph{conditional Rademacher average} is the quantity
\[
	\mathsf{R}_S=\mathbb{E}_\sigma\left[\sup_{r\in\range}R_S(r)\right],
\]
where $\mathbb{E}_\sigma$ denotes the expectation taken only w.r.t.~the random
variables $\sigma_i$, $1\le i\le\ell$ (i.e., conditionally on the sample).

The following result, which is at the core of statistical learning theory, gives
a bound to the maximum deviation between the empirical average of a range and
its true probability.

\begin{theorem}[Thm.~3.2~\citep{BoucheronBL05}]\label{thm:fundthmlearn}
	Let $S$ be a bag of $\ell$ elements from $D$, sampled independently
	according to the distribution $\nu$.  Then, with probability at least
	$1-\delta$,
	\[
		\sup_{r\in\range}|\nu(r)-\nu_S(r)|\le 2 \mathsf{R}_S
		+\sqrt{\frac{2\ln\frac{4}{\delta}}{\ell}}\enspace.
	\]
\end{theorem}

It is well known~\citep[Sect.~1.4.6]{Lugosi02} that using covering
numbers~\citep{AnthonyB99}, the chaining technique by~\citet{Dudley84}, and a
bound to covering numbers using the (empirical) VC-dimension $d$
by~\citet{Haussler95}, one can obtain that
\[
	\mathsf{R}_S\le c\sqrt{\frac{d}{|S|}}\enspace.
\]
A more refined analysis by~\citet{SridharanTR} allows us to incorporate the
maximum size of the intersection of a range with the set $S$ and obtain
\[
	\mathsf{R}_S\le c\max_{r\in\range}\sqrt{|r\cap
	S|}\frac{\sqrt{2d}}{|S|}\enspace.
\]
Note that this dependency on the maximum intersection is to be expected, as a
similar dependency appears in Massart's finite class lemma~\citep[Lemma
26.8]{ShalevSBD14}.

By combining this bound to the Rademacher averages with
Thm.~\ref{thm:fundthmlearn} we obtain Thm.~\ref{thm:eapproxempir}.
